{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9b9230f",
   "metadata": {},
   "source": [
    "# Create a synthetic dataset based on the Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a892ee1a",
   "metadata": {},
   "source": [
    "Since, we cannot distribute the tweets as per the Twitter Privacy Policy, we create synthetic tweets that are based on the tweets annotated by the Diego Lab, a Biomedical Informatics Lab at Arizona State University (ASU).\n",
    "\n",
    "To create synthetic tweets we - 1) translate the original tweet from English to German and back to English, to add variability and noise in the original text; 2) remove stop words. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcfaef9",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19e837bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "947ffca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: better_profanity in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (0.7.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.1.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install better_profanity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0efed6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "translate = boto3.client(service_name='translate', region_name='us-east-1', use_ssl=True)\n",
    "\n",
    "def get_translations(source_lang_code, destination_lang_code, text):\n",
    "    result = translate.translate_text(Text=text, \n",
    "                                      SourceLanguageCode=source_lang_code, \n",
    "                                      TargetLanguageCode=destination_lang_code)\n",
    "    TranslatedText = result.get('TranslatedText')\n",
    "    return TranslatedText\n",
    "\n",
    "def create_synthetic_text(text):\n",
    "    # translate the text, twice, to add noise\n",
    "    translated_result = get_translations('en', 'de', text)\n",
    "    result = get_translations('de', 'en', translated_result)\n",
    "    \n",
    "    # remove stop words\n",
    "    if text == result:\n",
    "        result = ' '.join([word for word in text.split() if word not in stopwords.words('english')])\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3f78ce",
   "metadata": {},
   "source": [
    "Note: To run the cell above ensure that the IAM role attached to the SageMaker notebook instance has perimissions to invoke the Amazon Translate API. For more information on attaching the necessary policies and adding trusted entites, refer to the documentation - [Creating a role to delegate permissions to an AWS service](https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_create_for-service.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc004c2",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ce23c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"adr_classify_twitter_data.csv\", lineterminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "236a27b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [text, tweet_id, user_id, label]\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecb15092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove profanity from the dataset\n",
    "from better_profanity import profanity\n",
    "\n",
    "df['has_profanity'] = df['text'].apply(lambda ele: True if profanity.contains_profanity(ele) else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51a9a0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['has_profanity'] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7946fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_synthetic'] = df['text'].apply(lambda ele: create_synthetic_text(ele))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea34f66c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    33\n",
       "1     1\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['text'] == df['text_synthetic']]['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "027a6dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove observations where the original text is the same as the augmented text\n",
    "df_syn = df[df['text'] != df['text_synthetic']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36adbd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34c75155",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "### Remove Twitter usernames\n",
    "import re\n",
    "df_syn['text_synthetic'] = df_syn['text_synthetic'].apply(lambda ele: re.sub('@[^\\s]+','', ele))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a612fd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_syn = df_syn[['text_synthetic', 'label']]\n",
    "df_syn.rename({'text_synthetic':'text'}, axis=1).to_csv(\"adr_classify_twitter_synthetic_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c818a88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f930835b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
